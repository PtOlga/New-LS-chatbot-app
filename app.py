import os
import streamlit as st
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import InMemoryVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from requests.exceptions import RequestException

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–µ—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ)
# load_dotenv(verbose=True)
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ –∫–æ–¥ –ª–æ–∫–∞–ª—å–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ `.env` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
is_local = os.path.exists(".env")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –µ—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
if is_local:
    load_dotenv(verbose=True)

# –ó–∞–≥—Ä—É–∂–∞–µ–º API-–∫–ª—é—á–∏ —á–µ—Ä–µ–∑ Streamlit secrets (–¥–ª—è –æ–±–ª–∞—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
    USER_AGENT = st.secrets["USER_AGENT"]
    LANGSMITH_TRACING = st.secrets["LANGSMITH_TRACING"] 
    LANGSMITH_ENDPOINT = st.secrets["LANGSMITH_ENDPOINT"]
    LANGSMITH_API_KEY = st.secrets["LANGSMITH_API_KEY"]
    LANGSMITH_PROJECT = st.secrets["LANGSMITH_PROJECT"]
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except FileNotFoundError:
    # –ï—Å–ª–∏ secrets.toml –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    USER_AGENT = os.getenv("USER_AGENT")
    LANGSMITH_TRACING = os.getenv("LANGSMITH_TRACING") 
    LANGSMITH_ENDPOINT = os.getenv("LANGSMITH_ENDPOINT")
    LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
    LANGSMITH_PROJECT = os.getenv("LANGSMITH_PROJECT")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–¥–∞–Ω—ã –ª–∏ API-–∫–ª—é—á–∏
if not GROQ_API_KEY:
    st.error("–û—à–∏–±–∫–∞: GROQ_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not USER_AGENT:
    st.error("–û—à–∏–±–∫–∞: USER_AGENT –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not LANGSMITH_TRACING:
    st.error("–û—à–∏–±–∫–∞: LANGSMITH_TRACING –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not LANGSMITH_ENDPOINT:
    st.error("–û—à–∏–±–∫–∞: LANGSMITH_ENDPOINT –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not LANGSMITH_API_KEY:
    st.error("–û—à–∏–±–∫–∞: LANGSMITH_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not LANGSMITH_PROJECT:
    st.error("–û—à–∏–±–∫–∞: LANGSMITH_PROJECT –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()
if not OPENAI_API_KEY :
    st.error("–û—à–∏–±–∫–∞: OPENAI_API_KEY  –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM
try:
    llm = ChatGroq(
        model_name="llama-3.3-70b-versatile",
        temperature=0.6,
        api_key=GROQ_API_KEY
    )
    print("[DEBUG] LLM —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
except Exception as e:
    print(f"[ERROR] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM: {e}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
embeddings_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large-instruct")
print("[DEBUG] –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
def load_english_pages(urls):
    english_docs = []
    for url in urls:
        if not any(lang in url for lang in ["/ru", "/ar", "/es", "/ch"]):  
            try:
                loader = WebBaseLoader(url)
                documents = loader.load()
                if documents:
                    english_docs.extend(documents)
                    print(f"[DEBUG] –ó–∞–≥—Ä—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —Å {url}")
            except RequestException as e:
                print(f"[ERROR] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
    return english_docs

# –ü—Ä–∏–º–µ—Ä URL, –≥–¥–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
urls = ["https://status.law/about", "https://status.law/", "https://status.law/contact"]
documents = load_english_pages(urls)

# –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
chunks = text_splitter.split_documents(documents)
print(f"[DEBUG] –†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
vector_store = InMemoryVectorStore.from_documents(chunks, embeddings_model)
retriever = vector_store.as_retriever()
print("[DEBUG] –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ–∑–¥–∞–Ω–æ")

# –ü—Ä–æ–º–ø—Ç –¥–ª—è –±–æ—Ç–∞
template = """
You are a helpful legal assistant that answers questions based on information from status.law.
Answer accurately and concisely.
Question: {question}
Only use the provided context to answer the question.
Context: {context}
"""
prompt = PromptTemplate.from_template(template)

# –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
def format_history(message_history):
    formatted = ""
    for msg in message_history:
        formatted += f"User: {msg['question']}\nBot: {msg['answer']}\n\n"
    return formatted

message_history = []

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
st.set_page_config(page_title="Legal Chatbot", page_icon="ü§ñ")
st.title("ü§ñ Legal Chatbot")
st.write("–≠—Ç–æ—Ç –±–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Å–∞–π—Ç–∞ status.law.")

# –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –≤–æ–ø—Ä–æ—Å–∞
user_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:")
if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å"):
    if user_input:
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
        retrieved_docs = retriever.get_relevant_documents(user_input)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        context_text = "\n\n".join([doc.page_content for doc in retrieved_docs])

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
        chain = (
            RunnableLambda(lambda x: {"context": context_text, "question": x["question"]}) 
            | prompt
            | llm
            | StrOutputParser()
        )

        # –ó–∞–ø—É—Å–∫ —Ü–µ–ø–æ—á–∫–∏
        response = chain.invoke({"question": user_input, "context": context_text})

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        message_history.append({"question": user_input, "answer": response})

        # –í—ã–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç
        st.write(response)
